prompt_template: "Given this AI generated Context:\n'{context}'\n\nPlease provide a very detailed and comprehensive Response to the Instruction and include your reasoning step by step. \n### Instruction:\n{query}\n### Response:"
inference_model:
  model_import_path: "ctransformers.AutoModelForCausalLM"
  model_inference_function: "from_pretrained"
  model_params:
    #model_path: "./models/wizardcoder-python-13b-v1.0.Q4_0.gguf"
    #model_type: "llama"
    #local_files_only: true
    model_path: "TheBloke/WizardCoder-Python-7B-V1.0-GGUF"
    model_file: "wizardcoder-python-7b-v1.0.Q4_K_M.gguf"
    model_type: "llama"
    local_files_only: false
    #model_path: "TheBloke/Starcoderplus-Guanaco-GPT4-15B-V1.0-GGML"
    #model_type: "gpt_bigcode"
    #local_files_only: false
    #model_path: "TheBloke/Octocoder-GGML"
    #model_type: "gpt_bigcode"
    #local_files_only: false  

    ## MODEL CONFIGURATION PARAMETERS (GPU 4090 - 24GB VRAM, CPU 5950x - 32 threads, 64GB RAM)
    #avx2 and gpu_layers are not compatible 
    #lib: "avx2"
    threads: 4
    batch_size: 1
    context_length: 10000
    max_new_tokens: 4096
    gpu_layers: 25
    reset: true
